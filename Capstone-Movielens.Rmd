---
title: "HarvardX: PH125.9x Data Science Capstone - Movielens Project"
author: "Golpira Elmi Assadzadeh, Ph.D."
date: "31/03/2020"
output: pdf_document

fontsize: 10pt
geometry: margin=1in

fig_width: 5 
fig_height: 3 
---
```{r, echo=TRUE}
knitr::opts_chunk$set(error = TRUE)
```

```{r, echo=TRUE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

\bf PROJECT OVERVIEW

The recommendation systems offered by companies such as Amazon utilize previously rated, browsed, or purchased items to recommend items of potential interest to buyers. In this project, our aim is to develop an machine learning algorithm to predict the movie ratings, and use it to recommend movies to users. The MovieLens dataset used in this project contains 10000054 movie ratings applied to 10677 movies by 69878 users and grouped into 797 distinct genres. The dataset is  collected by Harper and Konstan (2015) and is made available for public download through the GroupLens Research Group at the University of Minnesota. 

The data were first inspected in order to understand the pattern and data structure. Several plots have been created in ordere to visualize the effect of movies, users, movie age, and genres on average ratings. The edx dataset were then splitted into training and test sets and several different algorithms were tested to find the prediction with lowest RMSE. The final model were then used to calculate the Root Mean Square Error (RMSE) on validation datasets. The RMSE is a measure of the differences between values predicted by a model and the values observed (i.e., model accuracy), and is calculated as follows:

$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$
In calculating RMSE, one should be cognizant as larger errors have a disproportionately large effect on the result. In other words, RMSE is sensitive to outliers.


```{r setup, include=FALSE,  warning=FALSE}
################################
# Create edx set, validation set
################################
options(digits=10)

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(lubridate)

# MovieLens 10M dataset:
 # https://grouplens.org/datasets/movielens/10m/
 # http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
 download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
 colnames(movies) <- c("movieId", "title", "genres")
 movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                            title = as.character(title),
                                            genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
 edx <- movielens[-test_index,]
 temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
      semi_join(edx, by = "movieId") %>%
      semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
 edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

\bf COURSE INSTRUCTIONS: "The validation data should NOT be used for training your algorithm and 
should ONLY be used for evaluating the RMSE of your final algorithm. You should split the edx data into 
separate training and test sets to design and test your algorithm."

\bf INSPECTING THE MOVIELENS DATA

```{r, echo=TRUE}

number_of_rows<- nrow(movielens)
number_of_rows

number_of_distinct_movies<- n_distinct(movielens$movieId)
number_of_distinct_movies

number_of_distinct_genres<- n_distinct(movielens$genres)
number_of_distinct_genres

number_of_distinct_userIds<- n_distinct(movielens$userId)
number_of_distinct_userIds
```


\bf INSPECTING AND VISUALIZING THE EDX DATA

Evaluating edx dataset structure

```{r, echo=TRUE}
str(edx)
```

Printing a few rows from edx dataset

```{r, echo=TRUE}
head(edx)
```

Number of edx distinct movieIds

```{r, echo=TRUE}
n_distinct(edx$movieId)
```

Number of edx distinct genres

```{r, echo=TRUE}
n_distinct(edx$genres)
```

Number of edx distinct userIds

```{r, echo=TRUE}
n_distinct(edx$userId)
```

Add a column "year_rated" to the edx dataset and taking out timestamp column

```{r, echo=TRUE}
edx <- edx %>% mutate(year_rated = year(as_datetime(timestamp))) %>% select(-timestamp)
head(edx)
```

Calculating the age of movie and the difference beween the date movie was rated from when movie was released.

```{r, echo=TRUE}
edx <- edx %>% mutate(movie_age = 2020 - year, rating_date_range = year_rated - year)
head(edx)
```


\bf MOVIE EFFECT BY TITLE

Average rating for each movie plotted versus the number of ratings.
```{r, echo=TRUE}
movie_avgs <- edx %>% 
  group_by(title) %>% 
  summarize(number_of_movie_ratings=n(), avg_movie_rating = mean(rating)) %>%
  arrange(desc(avg_movie_rating)) 

movie_avgs %>% print(n=10)         # View top 10 rows of the table
```

The figure below shows the relationship between average movie ratings and frequency of ratings. The variation in movie ratings are much higher for movies that have been rated less often.

```{r, echo=TRUE}
movie_avgs %>% ggplot(aes(number_of_movie_ratings, avg_movie_rating)) +
  geom_point() + 
  geom_smooth(method="loess") + 
  ggtitle("Relationship between average movie ratings and frequency of ratings") +
  theme(plot.title = element_text(hjust = 0.5))  # centre the title
```


\bf USER EFFECT
Average rating grouped by userId.

```{r, echo=TRUE}
user_avgs <- edx %>% 
  group_by(userId) %>% 
  summarize(number_of_user_ratings=n(), avg_user_rating = mean(rating)) %>% arrange(avg_user_rating)

head(user_avgs)
```

The results show that userId #46 has highest average rating of 4.93

```{r, echo=TRUE}
user_avgs$userId[which.max(user_avgs$avg_user_rating)] 
```

and userId #579 has lowest average rating of 1.23

```{r, echo=TRUE}
user_avgs$userId[which.min(user_avgs$avg_user_rating)] 
```

\bf YEAR RATED EFFECT   

            ####ADD A NOTE HERE########

```{r, echo=TRUE}
year_avgs <- edx %>% 
  group_by(year_rated) %>% 
  summarize(avg_rating_by_year = mean(rating))
head(year_avgs)

year_avgs %>% 
  ggplot(aes( year_rated, avg_rating_by_year)) + 
  geom_point() +
  ggtitle("plot of average rating by year versus ratings year movie is rated") +
  theme(plot.title = element_text(hjust = 0.5))  # centre the title
```
                    
                     ####ADD A NOTE HERE########
                     
```{r, echo=TRUE}
edx %>%
  group_by(movieId) %>%
  summarize(n = n(), years = 2020 - first(year),
            title = title[1],
            rating = mean(rating)) %>%
  mutate(rate = n/years) %>%
  ggplot(aes(rate, rating)) +
  geom_point() +
  geom_smooth() +
  ggtitle("plot of average ratings versus ratings per year") +
  theme(plot.title = element_text(hjust = 0.5))  # centre the title
```

\bf MOVIE AGE EFFECT

Age of movie vs average movie rating

The plot shows that older movies have generally rated higher compared to newer movies.

```{r, echo=TRUE}
age_avgs <- edx %>% 
  group_by(movie_age) %>% 
  summarize(avg_rating_by_age = mean(rating))
head(age_avgs)

age_avgs %>%
  ggplot(aes(movie_age, avg_rating_by_age)) +
  geom_point() + 
  ggtitle("Relationship between movie age and average movie rating") +
  theme(plot.title = element_text(hjust = 0.5)) +  # centre the title
  geom_smooth(method="gam")
```


\bf GENRE EFFECT

Splitting movies into single genres

```{r, echo=TRUE}
single_genres <- edx %>% separate_rows(genres, sep ="\\|")
head(single_genres)
```

Total number of movies in each genre?

```{r, echo=TRUE}
number_of_movies_genres <- single_genres %>% group_by(genres) %>% summarize(number_movies_genre = n())
number_of_movies_genres
```

List of all genres

```{r, echo=TRUE}
number_of_movies_genres$genres
```

Distribution of ratings per genre

```{r, echo=TRUE}
genre_distribution <- single_genres %>%
  group_by(genres) %>%
  summarize(n=n()) %>%
  ungroup() %>%
  mutate(rating_per_genre = n/sum(n)) %>%
  arrange(desc(rating_per_genre)) %>% select(-n)
```

Plot of ratings per genre
The graph shows that movie ratings are also a function of genres, with Drama and Comedy having being the most frequently rated genres.

```{r, echo=TRUE, fig.align="left"}
genre_distribution %>%  
  ggplot(aes(reorder(genres, -rating_per_genre), rating_per_genre)) +
  geom_bar(stat = "identity", color="white", fill="blue") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

mean_rating_per_genre<- single_genres %>%
  group_by(genres) %>%
  summarize(mean_rating_by_genre=mean(rating)) %>%
  arrange(-mean_rating_by_genre)
```

Plot showing the average rating based on genres. Film-Noir has the highest average rating while Horror movies have the lowest average rating.

```{r, echo=TRUE, fig.align="left"}
single_genres %>% group_by(genres) %>%
  summarize(n = n(), avgerge_rating = mean(rating), se = sd(rating)/sqrt(n())) %>%
  filter(n >= 1000) %>%
  mutate(genres = reorder(genres, avgerge_rating)) %>%
  ggplot(aes(x = genres, y = avgerge_rating, ymin = avgerge_rating - 2*se, ymax = avgerge_rating + 2*se)) +
  geom_point() +
  geom_errorbar() +
  ggtitle ("Plot of average ratings based on genres") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(plot.title = element_text(hjust = 0.5))  # centre the title
```


\bf PREDICTIONS (TESTING DIFFERENT MODELS)

Splitting edx data into training and test sets.

```{r, echo=TRUE}
edx_test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.2, list = FALSE)
training_set <- edx[-edx_test_index,] 
test_set <- edx[edx_test_index,]
```


\bf DEFINING RMSE FUNCTION

```{r, echo=TRUE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2, na.rm =TRUE))
}
```


\bf BASE MODEL 

Predicting the same rating for all movies regardless of user

```{r, echo=TRUE}
mu_hat <- mean(training_set$rating) 
mu_hat

naive_rmse <- RMSE(test_set$rating, mu_hat) 
naive_rmse     


rmse_results <- tibble(method = "Base model_Averaging", RMSE = naive_rmse)
```

RMSE result for this model is 1.059609 which is too high.


\bf MOVIE EFFECTS

Some movies rated higher than others.

Because some movies rated more than others, it's not correct to average ratings for all movies altogether, rather, movie rate bias should be taken into account.

```{r, echo=TRUE}
mu <- mean(training_set$rating)
movie_avgs <- training_set %>%
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))

qplot(b_i, data = movie_avgs, bins = 20, color = I("white"), fill=I("blue"))

predicted_ratings <- mu + test_set %>% 
  left_join(movie_avgs, by='movieId') %>% 
  pull(b_i)

RMSE_movies<- RMSE(test_set$rating, predicted_ratings)

# adding the results to the rmse tibble for comparison
rmse_results<- add_row(rmse_results, method="Movie_Effect", RMSE=RMSE_movies)
```


\bf USER EFFECTS

Some users rated more than others.

Let’s compute the average rating for user u for those that have rated over 100 movies.

```{r, echo=TRUE, fig.align="left"}
training_set %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) +
  geom_histogram(bins = 20, color="white", fill = "blue") +
  ggtitle("Histogram of average rating for users who rated over 100 movies") +
  theme(plot.title = element_text(hjust = 0.5))  # centre the title

user_avgs <- training_set %>% left_join(movie_avgs, by='movieId') %>% group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>% 
  left_join(user_avgs, by='userId') %>% 
  mutate(pred = mu + b_i + b_u) %>% 
  pull(pred)

RMSE_user_movie<- RMSE(test_set$rating, predicted_ratings)
# addind the results to the rmse tibble for comparison
rmse_results<- add_row(rmse_results, method="User_Movie_Effect", RMSE=RMSE_user_movie)
```


\bf REGULARIZED MOVIE_USER

Penalizing low rated movies and user who rated less frequently 
(i.e., Choosing the tuning value for lambda)

```{r, echo=TRUE, fig.align="left"}
lambdas <- seq(0,5,0.5)
rmses <- sapply(lambdas, function(lam){
  mu <- mean(training_set$rating)
  
  b_i <- training_set %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n() + lam))
  
  b_u <- training_set %>%
    left_join(b_i, by='movieId') %>% 
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n() +lam))
  
  predicted_ratings <- training_set %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i +  b_u) %>% .$pred
  
  return(RMSE(predicted_ratings, training_set$rating))
})

plot(lambdas, rmses)

RMSE_REG_MOVIE_USER<-min(rmses)
lambdas[which.min(rmses)]  #lambda that minimizes RMSEs for MOVIE + USER

rmse_results<- add_row(rmse_results, method="regularized_User_Movie", RMSE=RMSE_REG_MOVIE_USER)
rmse_results
```


\bf USE THE REGULARIZED_MOVIE_USER TO PREDICT VALIDATION SET

```{r, echo=TRUE}
lam <- 0.5  # OBTAINED FROM TUNING RMSE_REG_MOVIE_USER
mu <- mean(validation$rating)

b_i <- validation %>%
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n() + lam))

b_u <- validation %>%
  left_join(b_i, by='movieId') %>% 
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n() +lam))

predicted_ratings <- validation %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i +  b_u) %>% .$pred

RMSE(predicted_ratings, validation$rating)
```










References:

F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872